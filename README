
Running Clus
------------

Clus is based on Java from <http://java.sun.com>. You will need Java 2 version 1.4.x or above to run Clus. Clus is a command line application and should be started from a command prompt (Windows) or X-Terminal (Unix).

To start Clus, enter the command:

java -jar /path/to/Clus.jar dataset

With /path/to/Clus.jar the location of Clus.jar in your Clus distribution and "dataset" the name of your settings file. The settings are briefly discussed below.

Try Clus first on the examples in the "data" folder.

E.g., as follows:

cd data/iris
clus -jar ../../Clus.jar iris

More information about Clus is available here:
<http://www.cs.kuleuven.be/~dtai/clus/>

Please feel free to contact <jan.struyf@cs.kuleuven.be> with any questions or comments about Clus.

Compiling Clus
--------------

(Windows)

cd C:\Clus\src
javac -cp ".;commons-math-1.0.jar" clus/Clus.java

(Unix)

cd /home/jan/Clus
javac -cp ".:commons-math-1.0.jar" clus/Clus.java

Running Clus (if you compiled from the source code)
---------------------------------------------------

(Windows)

cd path\to\appfile.s
java -cp "C:\Clus;C:\Clus\commons-math-1.0.jar;." clus.Clus appfile

(Unix)

cd path/to/appfile.s
java -cp "/home/jan/Clus:/home/jan/Clus/commons-math-1.0.jar:." clus.Clus appfile


Settings overview
-----------------

All settings with their default values are set in "dataset.s" with "dataset" the name of your data set (assuming your data set is "dataset.arff"). The resulting model is written to "dataset.out". The file "dataset.out" also contains the values of all settings; these can be copy & pasted to "dataset.s".

[General]
RandomSeed = 0
 	// Initializes the random number generator, used e.g. for
 	// computing the cross-validation partition.
XVal = 10
 	// Sets the number of folds for cross-validation
 	// To perform cross-validation, run: clus -xval appname

[Data]
File = weather.arff
 	// Sets the training data file
TestSet = None
 	// Sets the test data file (if it is a valid file name)
 	// or test set proportion (if it is a number, e.g., 0.33)
PruneSet = None
 	// Sets the prune data file (if it is a valid file name)
 	// or prune set proportion (if it is a number, e.g., 0.33)

[Attributes]
Target = 5
 	// Sets the index of the target attribute
 	// (Run clus -info appname to list all attributes.)
Disable = 6
 	// Disables some attributes (e.g., "5,7-8")
Key = None
 	// Sets the index of the key attribute
Weights = Normalize
 	// Normalize numeric attributes

[Model]
MinimalWeight = 2.0
 	// Do not generate splits with less than 2 examples in
 	// one of the subtrees

[Tree]
MaxDepth = Infinity
 	// Stop building the tree at the given depth
ConvertToRules = No
 	// Convert the tree to a set of rules

[Numeric]
FTest = 1.0
 	// Sets the f-test stopping criterion for multi-objective
 	// regression

[Constraints]
Syntactic = None
 	// Sets the file with syntactic constraints
 	// (i.e., a partial tree)
MaxSize = Infinity
 	// Sets the maximum size for Garofalakis pruning
MaxError = Infinity
 	// Sets the maximum error for Garofalakis pruning

[Output]
AllFoldModels = Yes
 	// Output the model built in each of the cross-validation folds
AllFoldErrors = No
 	// Output error measures for each fold
TrainErrors = Yes
 	// Output training error measures
UnknownFrequency = No
 	// Show in each node of the tree the proportion of examples
 	// that had a missing value for the test stored in the node
BranchFrequency = No
 	// Show in each node, the proportion of examples for which
 	// the test stored in the node succeeds
WriteTestSetPredictions = No
 	// Write the predictions obtained on the test set to a
 	// file

[Beam]
SizePenalty = 0.1
 	// Sets the size penalty parameter used in the beam heuristic
BeamWidth = 10
 	// Sets the width of the beam (number of trees)
MaxSize = Infinity
 	// Sets the maximum size constraint

